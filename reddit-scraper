import os
from dotenv import load_dotenv
import csv
import sqlite3
import spacy
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import praw
import re

# --- Initialize SQL lite db ---
conn = sqlite3.connect("reddit_bifl.db")
cursor = conn.cursor()

cursor.execute('''
CREATE TABLE IF NOT EXISTS comments (
    id TEXT PRIMARY KEY,
    post_id TEXT,
    body TEXT,
    sentiment REAL,
    product TEXT
)
''')
conn.commit()

# --- Create NLP using VADER ---
analyzer = SentimentIntensityAnalyzer()
nlp = spacy.load("en_core_web_sm")

product_like_terms = [
    "boots", "knife", "thermos", "jacket", "watch", "backpack",
    "blender", "cast iron", "wallet", "mug", "tools", "chair", "flashlight",
    "socks", "pen", "notebook", "headphones", "grill", "skillet"
]
# helper function for extracing text from products
def extract_potential_products(text):
    doc = nlp(text)
    keywords = []
    for chunk in doc.noun_chunks:
        chunk_text = chunk.text.strip().lower()
        if any(word in chunk_text for word in product_like_terms):
            if len(chunk_text.split()) <= 4 and not chunk_text.startswith(("i", "mine", "you", "thanks")):
                keywords.append(chunk_text)
    return keywords

def title_mentions_product(title):
    title = title.lower()
    return any(term in title for term in product_like_terms)



# --- To run on your device, create a .env folder in the main folder ---
#   CLIENT_ID=your_reddit_client_id
#   CLIENT_SECRET=your_reddit_client_secret
#   USER_AGENT=your_script_name_by_/u/your_username

load_dotenv()
client_id = os.getenv("CLIENT_ID")
client_secret = os.getenv("CLIENT_SECRET")
user_agent = os.getenv("USER_AGENT")

# --- TEST LOGIN CREDENTIALS ---
""" 

print(client_id)
print(client_secret)
print(user_agent)

"""


reddit = praw.Reddit(
    client_id=client_id,
    client_secret=client_secret,
    user_agent=user_agent
)

# --- SCRAPE POSTS AND COMMENTS  --- 
for post in reddit.subreddit("BuyItForLife").hot(limit=30):
    if not title_mentions_product(post.title):
        continue  # Skip posts that don't mention a product

    print(f"Scraping product post: {post.title}")
    title_product = post.title.strip().lower()

    post.comments.replace_more(limit=0)
    for comment in post.comments.list():
        if comment.body:
            sentiment = analyzer.polarity_scores(comment.body)['compound']
            products = extract_potential_products(comment.body)

            # Always associate comment with product from title
            products = products if products else [title_product]

            for product in products:
                try:
                    cursor.execute('''
                        INSERT OR IGNORE INTO comments (id, post_id, body, sentiment, product)
                        VALUES (?, ?, ?, ?, ?)
                    ''', (comment.id, post.id, comment.body, sentiment, product))
                except Exception as e:
                    print(f"Error inserting comment {comment.id}: {e}")

conn.commit()
conn.close()
print("END")