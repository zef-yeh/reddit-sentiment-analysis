import os
import sqlite3
from dotenv import load_dotenv
import praw
from fuzzywuzzy import process
import spacy

# --- To run on your device, create a .env folder in the main folder ---
#   CLIENT_ID=your_reddit_client_id
#   CLIENT_SECRET=your_reddit_client_secret
#   USER_AGENT=your_script_name_by_/u/your_username

load_dotenv()
client_id = os.getenv("CLIENT_ID")
client_secret = os.getenv("CLIENT_SECRET")
user_agent = os.getenv("USER_AGENT")

# --- TEST LOGIN CREDENTIALS ---
""" 

print(client_id)
print(client_secret)
print(user_agent)

"""
reddit = praw.Reddit(
    client_id=client_id,
    client_secret=client_secret,
    user_agent=user_agent
)

# create nlp and sql db
nlp = spacy.load("en_core_web_sm")
conn = sqlite3.connect("reddit_bifl.db")
cursor = conn.cursor()

# load in catalog
cursor.execute("SELECT product_normalized FROM catalog")
catalog = [row[0] for row in cursor.fetchall()]

# create table
cursor.execute('''
CREATE TABLE IF NOT EXISTS matched_posts (
    id TEXT PRIMARY KEY,
    title TEXT,
    matched_product TEXT
)
''')
conn.commit()

def normalize(text):
    return ' '.join(text.lower().strip().split())

def match_to_catalog(text, threshold=85):
    match, score = process.extractOne(normalize(text), catalog)
    return match if score >= threshold else None


# --- SCRAPE POSTS AND COMMENTS  --- 
for post in reddit.subreddit("BuyItForLife").top(time_filter="year", limit=100):
    title = post.title
    doc = nlp(title)
    found = False
    for chunk in doc.noun_chunks:
        match = match_to_catalog(chunk.text)
        if match:
            print(f"Matched: {chunk.text} â†’ {match}")
            cursor.execute("INSERT OR IGNORE INTO matched_posts VALUES (?, ?, ?)",
                           (post.id, title, match))
            found = True
            break

if not found:
    print(f"No match: {title}")

conn.commit()
conn.close()
print("END")